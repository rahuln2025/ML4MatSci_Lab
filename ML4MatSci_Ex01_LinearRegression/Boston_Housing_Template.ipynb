{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cafbd8",
   "metadata": {},
   "source": [
    "## Linear Regression with Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dabaaf1",
   "metadata": {},
   "source": [
    "##### SOME RULES: \n",
    "\n",
    "- Provide some documentation to your code in the form of comments. Your code should be understandable and easy to navigate. \n",
    "- Answer the questions in the basic data analysis section by typing in the markdown cell. \n",
    "- Ensure that your code runs completely without errors and your model trains over the epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03bbeb7",
   "metadata": {},
   "source": [
    "### Basic Data Analysis\n",
    "\n",
    "#### Tasks: \n",
    "\n",
    "- Load dataset as a Pandas Dataset\n",
    "- Use Pandas functions to perform the following: \n",
    "    - 1) Get info about the columns: the number of entries in each column, the datatype of the entries in each column.   \n",
    "    - 2) Get basic statistical estimators of each column of the data, i.e. mean, standard deviation, min, 25%, 50% and 75% quantiles, max.\n",
    "    - 3) Plot histograms of all the features (columns) in data. \n",
    "    - 4) Plot scatter plots of each feature vs the target ('medv'). \n",
    "    - 5) (Optional) Check correlations of each feature with the target. Use the Pearson correlation coefficient for this. \n",
    "    - 6) (Optional) Plot a heatmap of these correlations using the 'heatmap' function of the Seaborn library. \n",
    "\n",
    "Note: The above tasks can be performed by simply using certain methods of the Pandas library. You are also free to make your own functions for these. But with Pandas, you can do these tasks very easily.\n",
    "\n",
    "- Answer the following questions in short:\n",
    "    - 1) How many samples are there? \n",
    "    - 2) How many features are there? \n",
    "    - 3) Are there any columns with non-numeric entries? \n",
    "    - 4) Are there any missing (null) entries in the data?\n",
    "    - 5) From the basic statistical estimators, answer the follwing: \n",
    "        - Are all the features on the same scale, i.e. do they all have the same range, means and standard deviations?\n",
    "        - Is the 'chas' feature a categorical? \n",
    "    - 6) Observe the histograms. Are any of the distributions symmetric? Do any of the distrubtions show outliers? \n",
    "    - 7) Observe the scatter plots. Select four features that, based on your observation, show a strong correlation with the target 'medv'. \n",
    "    - 8) (Optional) List the correlation coefficients of all the features with the target 'medv' in descending order. \n",
    "    - 9) (Optional) From the heatmap, do you observe if any of the features are strongly correlated with each other? If yes, name any two pairs of such correlated features. (Here, we do not check the correlation between the feature and the target, but we check if any of the features are strongly interdependent. Strong correlation means that the absoulute value of the Pearson correlation coefficient is >= 0.5)\n",
    "    - 10) (Optional) Having interdepent features is a good thing or a bad thing for linear regression? \n",
    "\n",
    "\n",
    "Note: Correct answers to the optional tasks and questions shall be awarded bonus points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67166ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset. Ensure that the path is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bb7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94227a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d82c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5b950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eda81427",
   "metadata": {},
   "source": [
    "### Preparing Training and Testing Data\n",
    "\n",
    "#### Tasks:\n",
    "\n",
    "\n",
    "   - 1) From the basic data analysis, list the four features that you have considered for the linear regression model. \n",
    "   - 2) Extract the data of these four features from the dataset. \n",
    "   - 3) Create X (design) matrix.\n",
    "   - 4) Create y (label/target) vector. \n",
    "   - 5) Create a train test split of the X matrix and y vector (80 % training, 20 % testing). Print number of training samples and the number of test samples. \n",
    "   - 6) Scale these samples using the MinMaxScaler from the 'scikit learn' library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcb234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9efb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a535134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ae0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c6728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c12386a",
   "metadata": {},
   "source": [
    "### Model Setup and Training\n",
    "\n",
    "#### Tasks: \n",
    "\n",
    "   - 1) Create a random initialization function that initializes the weights randomly. \n",
    "   - 2) Create a function that computes loss. Use MSE loss. \n",
    "   - 3) Create a function that results the prediction vector by taking the weights and X_train matrix as input arguments. \n",
    "   - 4) Create functions for mini-batch gradient descent, stochastic gradient descent and batch gradient descent with regularization.\n",
    " \n",
    "- 5) Train the model.\n",
    "        - Use the functions created in previous tasks for training the model. \n",
    "        - Save the training losses over all epochs. \n",
    "        - Plot the change in the losses over epochs.\n",
    "\n",
    "\n",
    "Note: Choose the learning rate and regularlization parameters suitably. In the loss vs. epochs plot, an overall decrease in the loss over epochs should be observable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80b5ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885c862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73bb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdd69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c750107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d78ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5315a730",
   "metadata": {},
   "source": [
    "### Test the Model Performance\n",
    "\n",
    "#### Tasks: \n",
    "    \n",
    "   - 1) Use the trained weights and the testing data to make predictions. \n",
    "   - 2) Calculate the testing loss using these predictions and the test labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12854b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e89b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9236cb59",
   "metadata": {},
   "source": [
    "### Effect of Variations of Gradient Descent\n",
    "\n",
    "#### Tasks: \n",
    "    \n",
    "   - 1) Train the model using batch gradient descent. Plot the loss vs. epoch curve. Compute and print the testing loss. \n",
    "   - 2) Train the model using stochastic gradient descent. Plot the loss vs. epoch curve. Compute and print the testing loss. \n",
    "   - 3) Train the model using mini-batch gradient descent. Plot the loss vs. epoch curve. Compute and print the testing loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e1288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f211be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc90dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c746525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661bc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132d5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8beb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "208747bb",
   "metadata": {},
   "source": [
    "### Effect of varying regularization lambdas\n",
    "\n",
    "#### Tasks: \n",
    "    \n",
    "Fix the number of epochs to 1000. Use the following regularization parameter values: [10, 1, 0.1, 0.05, 0.01, 0.005].\n",
    "   - 1) Train model using batch gradient descent with the regularization parameter values in the above list. \n",
    "   - 2) Plot the loss vs. epoch curves for different regularization parameter values in one plot for comparison. \n",
    "   - 3) Compute testing losses using the weights obtained after training the model for different regularization parameter values and print them. \n",
    "   - 4) Provide the learning rate and regularization parameters of the model that perform's the best. \n",
    "   \n",
    "Note: The best performing model is the one which has the least testing loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b2153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe4f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2f742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b5571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ddb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
